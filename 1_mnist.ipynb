{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/train-images-idx3-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import gzip\n",
    "import os\n",
    "\n",
    "IMAGE_SIZE = 28\n",
    "NUM_CHANNELS = 1\n",
    "PIXEL_DEPTH = 255\n",
    "VALIDATION_SIZE = 5000\n",
    "\n",
    "data_path = \"./data\"\n",
    "train_data_path = os.path.join(data_path, \"train-images-idx3-ubyte.gz\")\n",
    "train_label_path = os.path.join(data_path, \"train-labels-idx1-ubyte.gz\")\n",
    "test_data_path = os.path.join(data_path, \"t10k-images-idx3-ubyte.gz\")\n",
    "test_label_path = os.path.join(data_path, \"t10k-labels-idx1-ubyte.gz\")\n",
    "print(train_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_data(filename, num_images):\n",
    "    with gzip.open(filename) as bytestream:\n",
    "        bytestream.read(16)\n",
    "        buf = bytestream.read(IMAGE_SIZE * IMAGE_SIZE * num_images * NUM_CHANNELS)\n",
    "        data = np.frombuffer(buf, dtype=np.uint8).astype(np.float32)\n",
    "        data = (data - (PIXEL_DEPTH / 2.0)) / PIXEL_DEPTH\n",
    "        data = data.reshape(num_images, IMAGE_SIZE, IMAGE_SIZE, NUM_CHANNELS)\n",
    "    return data\n",
    "    \n",
    "def extract_labels(filename, num_images):\n",
    "    with gzip.open(filename) as bytestream:\n",
    "        bytestream.read(8)\n",
    "        buf = bytestream.read(1 * num_images)\n",
    "        labels = np.frombuffer(buf, dtype=np.uint8).astype(np.int64)\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = extract_data(train_data_path, 60000)\n",
    "test_data = extract_data(test_data_path, 10000)\n",
    "train_labels = extract_labels(train_label_path, 60000)\n",
    "test_labels = extract_labels(test_label_path, 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x13b7c04e0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "validation_data = train_data[:VALIDATION_SIZE]\n",
    "validation_labels = train_labels[:VALIDATION_SIZE]\n",
    "train_data = train_data[VALIDATION_SIZE:]\n",
    "train_labels = train_labels[VALIDATION_SIZE:]\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "digital = train_data[0].reshape(28, 28)\n",
    "plt.imshow(digital, cmap=matplotlib.cm.binary, interpolation=\"nearest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-6-6fb7fa2c950e>:32: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.conv2d instead.\n",
      "WARNING:tensorflow:From /anaconda3/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From <ipython-input-6-6fb7fa2c950e>:42: max_pooling2d (from tensorflow.python.layers.pooling) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.max_pooling2d instead.\n",
      "WARNING:tensorflow:From <ipython-input-6-6fb7fa2c950e>:46: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dense instead.\n"
     ]
    }
   ],
   "source": [
    "height = 28\n",
    "width = 28\n",
    "channels = 1\n",
    "n_inputs = height * width\n",
    "\n",
    "conv1_fmaps = 32\n",
    "conv1_ksize = 3\n",
    "conv1_stride = 1\n",
    "conv1_pad = \"SAME\"\n",
    "\n",
    "conv2_fmaps = 64\n",
    "conv2_ksize = 3\n",
    "conv2_stride = 2\n",
    "conv2_pad = \"SAME\"\n",
    "\n",
    "pool3_ksize = 2\n",
    "pool3_stride = 2\n",
    "pool3_pad = \"VALID\"\n",
    "pool3_fmaps = 64\n",
    "\n",
    "n_fc1 = 64\n",
    "n_outputs = 10\n",
    "\n",
    "with tf.name_scope(\"inputs\"):\n",
    "    X = tf.placeholder(tf.float32, shape=[None, IMAGE_SIZE, IMAGE_SIZE, channels], name=\"X\")\n",
    "#     X_reshaped = tf.reshape(X, shape=[-1, IMAGE_SIZE, IMAGE_SIZE, channels])\n",
    "    y = tf.placeholder(tf.int32, shape=[None], name=\"y\")\n",
    "    \n",
    "with tf.name_scope(\"conv1\"):\n",
    "    conv1 = tf.layers.conv2d(X, filters=conv1_fmaps, kernel_size=conv1_ksize,\n",
    "                        strides=conv1_stride, padding=conv1_pad,\n",
    "                        activation=tf.nn.relu)\n",
    "    \n",
    "with tf.name_scope(\"conv2\"):\n",
    "    conv2 = tf.layers.conv2d(conv1, filters=conv2_fmaps, kernel_size=conv2_ksize,\n",
    "                        strides=conv2_stride, padding=conv2_pad,\n",
    "                        activation=tf.nn.relu)\n",
    "\n",
    "with tf.name_scope(\"pool3\"):\n",
    "#     pool3 = tf.nn.max_pool(conv2, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding=\"VALID\")\n",
    "    pool3 = tf.layers.max_pooling2d(conv2, pool_size=pool3_ksize, strides=pool3_stride,\n",
    "                                    padding=pool3_pad, name=\"pool3\")\n",
    "    pool3_flat = tf.reshape(pool3, shape=[-1, pool3_fmaps * 7 * 7])\n",
    "    \n",
    "with tf.name_scope(\"fc1\"):\n",
    "    fc1 = tf.layers.dense(pool3_flat, n_fc1, activation=tf.nn.relu)\n",
    "\n",
    "with tf.name_scope(\"output\"):\n",
    "    logits = tf.layers.dense(fc1, n_outputs)\n",
    "    Y_proba = tf.nn.softmax(logits, name=\"Y_proba\")\n",
    "\n",
    "with tf.name_scope(\"train\"):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits, labels=y)\n",
    "    loss = tf.reduce_mean(xentropy)\n",
    "    optimizer = tf.train.AdamOptimizer()\n",
    "    training_op = optimizer.minimize(loss)\n",
    "\n",
    "with tf.name_scope(\"eval\"):\n",
    "    correct = tf.nn.in_top_k(logits, y, 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
    "    \n",
    "with tf.name_scope(\"init_and_save\"):\n",
    "    init = tf.global_variables_initializer()\n",
    "    saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 10\n",
    "batch_size = 100\n",
    "n_batches = len(train_labels) // batch_size\n",
    "\n",
    "def fetch_batch(epoch, batch_index, batch_size):\n",
    "    np.random.seed(epoch * n_batches + batch_index)\n",
    "    indices = np.random.randint(len(train_labels), size=batch_size)\n",
    "    X_batch = train_data[indices]\n",
    "    y_batch = train_labels[indices]\n",
    "    return X_batch, y_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Train accuracy: 1.0 Validation accuracy: 0.9772\n",
      "Epoch: 1 Train accuracy: 0.99 Validation accuracy: 0.982\n",
      "Epoch: 2 Train accuracy: 1.0 Validation accuracy: 0.9852\n",
      "Epoch: 3 Train accuracy: 0.99 Validation accuracy: 0.9852\n",
      "Epoch: 4 Train accuracy: 1.0 Validation accuracy: 0.9864\n",
      "Epoch: 5 Train accuracy: 1.0 Validation accuracy: 0.9856\n",
      "Epoch: 6 Train accuracy: 0.99 Validation accuracy: 0.9872\n",
      "Epoch: 7 Train accuracy: 1.0 Validation accuracy: 0.9868\n",
      "Epoch: 8 Train accuracy: 1.0 Validation accuracy: 0.986\n",
      "Epoch: 9 Train accuracy: 1.0 Validation accuracy: 0.99\n",
      "Final test accuracy: 0.9906\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for epoch in range(n_epochs):\n",
    "        for iteration in range(n_batches):\n",
    "            X_batch, y_batch = fetch_batch(epoch, iteration, batch_size)\n",
    "#             X_batch = np.reshape(X_batch, [-1, n_inputs])\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "        acc_train = accuracy.eval(feed_dict={X: X_batch, y: y_batch})\n",
    "        acc_validation = accuracy.eval(feed_dict={X: validation_data, y: validation_labels})\n",
    "\n",
    "        print(\"Epoch:\", epoch, \"Train accuracy:\", acc_train, \"Validation accuracy:\", acc_validation)\n",
    "        \n",
    "        save_path = saver.save(sess, \"./my_mnist_model\")\n",
    "    \n",
    "    acc_test = accuracy.eval(feed_dict={X: test_data, y: test_labels})\n",
    "    print(\"Final test accuracy:\", acc_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
